{
  # Spark relation com.vesoft.exchange.common.config
  spark: {
    app: {
      name: Nebula Exchange 2.0
    }

    master:local

    driver: {
      cores: 1
      maxResultSize: 1G
    }

    executor: {
        memory:1G
    }

    cores:{
      max: 16
    }
  }

  # if the hive is hive-on-spark with derby modeï¼Œ you can ignore this hive configure
  # get the com.vesoft.exchange.common.config values from file $HIVE_HOME/conf/hive-site.xml or hive-default.xml

    hive: {
      warehouse: "hdfs://NAMENODE_IP:9000/apps/svr/hive-xxx/warehouse/"
      connectionURL: "jdbc:mysql://your_ip:3306/hive_spark?characterEncoding=UTF-8"
      connectionDriverName: "com.mysql.jdbc.Driver"
      connectionUserName: "user"
      connectionPassword: "password"
    }

  # Nebula Graph relation com.vesoft.exchange.common.config
  nebula: {
    address:{
      graph:["127.0.0.1:9669", "127.0.0.1:9670", "127.0.0.1:9671"]
      meta:["127.0.0.1:9559", "127.0.0.1:9560", "127.0.0.1:9561"]
    }
    user: root
    pswd: nebula
    space: test_string

    # parameters for SST import, not required
    path:{
        local:"/tmp"
        remote:"/sst"
        hdfs.namenode: "hdfs://name_node:9000"
    }

    # nebula client connection parameters
    connection {
      timeout: 3000
      retry: 3
    }

    # nebula client execution parameters
    execution {
      retry: 3
    }

    error: {
      # max number of failures, if the number of failures is bigger than max, then exit the application.
      max: 32
      # failed import job will be recorded in output path
      output: /tmp/errors
    }

    # use google's RateLimiter to limit the requests send to NebulaGraph
    rate: {
      # the stable throughput of RateLimiter
      limit: 1024
      # Acquires a permit from RateLimiter, unit: MILLISECONDS
      # if it can't be obtained within the specified timeout, then give up the request.
      timeout: 1000
    }
  }

  # Processing tags
  # There are tag com.vesoft.exchange.common.config examples for different dataSources.
  tags: [
    {
      name: person
      type: {
        source: csv
        sink: client
      }
      path: "file://src/test/resources/data.csv"
      fields: [col1,col2,col3,col4,col5,col6,col7,col8,col9,col10,col11,col12,col13,col14]
      nebula.fields: [col1,col2,col3,col4,col5,col6,col7,col8,col9,col10,col11,col12,col13,col14]
      vertex: {
        field:id
        #policy:hash
      }
      header:true
      batch: 2
      partition: 5
    }
  ]

  # There are tag com.vesoft.exchange.common.config examples for different dataSources.
    edges: [
      {
        name: friend
        type: {
          source: csv
          sink: client
        }
        path: "file://src/test/resources/data.csv"
        fields: [col1,col2,col3,col4,col5,col6,col7,col8,col9,col10,col11,col12,col13,col14]
        nebula.fields: [col1,col2,col3,col4,col5,col6,col7,col8,col9,col10,col11,col12,col13,col14]
        source: {
          field:src
          #policy:hash
        }
        target: {
          field:dst
          #policy:hash
        }
        header:true
        batch: 2
        partition: 5
      }
    ]
}
